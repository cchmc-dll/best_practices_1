{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1df688-30d2-4fb4-964e-c844b41e5e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob \n",
    "import boto3 \n",
    "import os \n",
    "import sys \n",
    "from multiprocessing.pool import ThreadPool \n",
    "\n",
    "# target location of the files on S3  \n",
    "\n",
    "S3_BUCKET_NAME = 'my_bucket' \n",
    "S3_FOLDER_NAME = 'data-files' \n",
    "\n",
    "# Enter your own credentials file profile name below\n",
    "\n",
    "AWS_PROFILE='my_profile' \n",
    "\n",
    "\n",
    "# Source location of files on local system \n",
    "\n",
    "DATA_FILES_LOCATION   = 'c:/mydata/fp*.dat'  \n",
    "\n",
    "session = boto3.Session(profile_name=AWS_PROFILE) \n",
    "\n",
    "s3 = session.client('s3') \n",
    "\n",
    "# The list of files we're uploading to S3 \n",
    "\n",
    "filenames =  glob.glob(DATA_FILES_LOCATION) \n",
    "\n",
    "\n",
    "def upload(myfile): \n",
    "\n",
    "    s3_file = f\"{S3_FOLDER_NAME}/{os.path.basename(myfile)}\" \n",
    "\n",
    "    s3.upload_file(myfile, S3_BUCKET_NAME, s3_file) \n",
    "\n",
    "\n",
    "# Number of pool processes is a guestimate - I've set \n",
    "# it to twice number of files to be processed \n",
    "\n",
    "pool = ThreadPool(processes=len(filenames)*2) \n",
    "\n",
    "  \n",
    "\n",
    "pool.map(upload, filenames)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
